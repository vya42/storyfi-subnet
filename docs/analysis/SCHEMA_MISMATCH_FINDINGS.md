# Schema Mismatch Findings

## Test Results Summary

| Task Type | Score | Grade | Status |
|-----------|-------|-------|--------|
| Blueprint | 80.0/100 | Excellent | âœ… PASS |
| Characters | 52.3/100 | Pass | âš ï¸ LOW |
| Story Arc | 35.0/100 | Fail | âŒ FAIL |
| Chapters | 25.0/100 | Fail | âŒ FAIL |
| **Average** | **48.1/100** | **Pass** | **âš ï¸ NEEDS FIX** |

## Key Findings

### âœ… Validator Scoring System Works Correctly

The scoring system itself is functioning properly:
- âœ… Technical scoring (JSON validity, time, schema) - Working
- âœ… Structure scoring (field completeness, logic) - Working
- âœ… Content scoring (relevance, fluency, originality) - Working

### âš ï¸ Schema Mismatches Detected

The issue is that **Gemini-generated responses don't match expected schemas** in the scoring system.

## Detailed Mismatch Analysis

### 1. Blueprint Task - âœ… PASS (80/100)

**Expected Schema**: âœ… Matches
```json
{
  "title": str,
  "genre": str,
  "setting": str,
  "core_conflict": str,
  "themes": [str],
  "tone": str,
  "target_audience": str
}
```

**Status**: Gemini generates this correctly. No changes needed.

---

### 2. Characters Task - âš ï¸ LOW (52.3/100)

**Expected Schema**:
```json
{
  "characters": [
    {
      "id": "protagonist|ally|rival|mentor|wildcard",  // âŒ Missing
      "name": str,
      "archetype": str,                                // âŒ Generated as "role"
      "background": str,
      "motivation": str,
      "skills": [str],                                 // âŒ Missing
      "personality_traits": [str],                     // âŒ Generated as "personality"
      "relationships": {                               // âŒ Generated as [str]
        "character_id": "relationship_type"
      }
    }
  ]
}
```

**What Gemini Generated**:
```json
{
  "characters": [
    {
      "name": str,
      "role": str,          // Should be "archetype"
      "personality": str,   // Should be "personality_traits": [str]
      "background": str,
      "motivation": str,
      "arc": str,           // Not in expected schema
      "relationships": [str] // Should be {"id": "type"}
    }
  ]
}
```

**Issues**:
1. Missing `id` field (protagonist/ally/rival/mentor/wildcard)
2. Missing `skills` array
3. `role` should be `archetype`
4. `personality` should be `personality_traits` (array)
5. `relationships` format is wrong (array vs object)

**Impact**: Schema completeness dropped from 10 â†’ 6 points

---

### 3. Story Arc Task - âŒ FAIL (35/100)

**Expected Schema**:
```json
{
  "title": str,              // âŒ Missing
  "description": str,        // âŒ Missing
  "chapters": [              // âŒ Missing
    {
      "id": int,
      "title": str,
      "description": str,
      "storyProgress": float
    }
  ],
  "arcs": {                  // âŒ Missing
    "act1": {"chapters": [1, 2, 3]},
    "act2a": {"chapters": [4, 5, 6]},
    "act2b": {"chapters": [7, 8, 9]},
    "act3": {"chapters": [10, 11, 12]}
  },
  "themes": {},              // âŒ Missing
  "hooks": {}                // âŒ Missing
}
```

**What Gemini Generated**:
```json
{
  "three_act_structure": {   // Not in expected schema
    "act_1_setup": str,
    "act_2_confrontation": str,
    "act_3_resolution": str
  },
  "major_plot_points": [...], // Not in expected schema
  "pacing": str,              // Not in expected schema
  "climax": str,
  "resolution": str
}
```

**Issues**: Completely different schema! Gemini generated a narrative description schema instead of the structured 12-chapter schema.

**Impact**: Schema completeness = 0 points (none of the required fields present)

---

### 4. Chapters Task - âŒ FAIL (25/100)

**Expected Schema**:
```json
{
  "chapters": [
    {
      "id": int,             // âŒ Generated as "chapter_number"
      "title": str,
      "content": str,        // âŒ Generated as "summary"
      "choices": [           // âŒ Missing
        {
          "text": str,
          "nextChapter": int,
          "consequences": {}
        }
      ]
    }
  ]
}
```

**What Gemini Generated**:
```json
{
  "chapters": [
    {
      "chapter_number": int, // Should be "id"
      "title": str,
      "summary": str,        // Should be "content" (1000+ chars)
      "key_events": [str],   // Not in expected schema
      "character_development": str, // Not in expected schema
      "cliffhanger": str     // Not in expected schema
    }
  ]
}
```

**Issues**:
1. `id` field missing (has `chapter_number` instead)
2. `content` missing (has `summary` instead, which is too short)
3. `choices` array completely missing
4. Extra fields not in schema

**Impact**: Schema completeness = 0 points

---

## Root Cause Analysis

### Why Schema Mismatches Occurred?

The test integration script used **simplified prompts** that ask Gemini to generate natural story schemas, but the **scoring system expects specific structured schemas** designed for:

1. **Interactive Branching Stories**: With choices, consequences, and narrative flow
2. **12-Chapter Structure**: With progress tracking (0.0 â†’ 1.0)
3. **Character Relationships**: As a graph (character_id â†’ relationship_type)
4. **4-Act Structure**: With chapter mappings

### What This Means

The Miner prompts need to be **very specific and structured** to generate responses that match the scoring schema. Generic "write a story" prompts won't work.

---

## Recommended Fixes

### Option 1: Update Miner Prompts (Recommended)

Update `neurons/miner_gemini.py` prompts to match expected schemas:

#### Characters Prompt Example:
```python
CHARACTERS_PROMPT = """ä½ æ˜¯è§’è‰²è®¾è®¡å¸ˆã€‚ä¸ºæ•…äº‹åˆ›å»º5ä¸ªè§’è‰²ã€‚

è¾“å‡ºJSONæ ¼å¼ï¼ˆä¸¥æ ¼éµå®ˆï¼‰ï¼š
{
  "characters": [
    {
      "id": "protagonist|ally|rival|mentor|wildcard",
      "name": "è§’è‰²å",
      "archetype": "è§’è‰²åŸå‹ï¼ˆè‹±é›„ã€æ™ºè€…ã€å›é€†è€…ç­‰ï¼‰",
      "background": "èƒŒæ™¯æ•…äº‹ï¼ˆ100-200å­—ï¼‰",
      "motivation": "è¡ŒåŠ¨åŠ¨æœº",
      "skills": ["æŠ€èƒ½1", "æŠ€èƒ½2", "æŠ€èƒ½3"],
      "personality_traits": ["æ€§æ ¼1", "æ€§æ ¼2", "æ€§æ ¼3"],
      "relationships": {
        "other_character_id": "relationship_type"
      }
    }
  ]
}

å¿…é¡»åˆ›å»º5ä¸ªè§’è‰²ï¼š
1. protagonist (ä¸»è§’)
2. ally (ç›Ÿå‹)
3. rival (å¯¹æ‰‹)
4. mentor (å¯¼å¸ˆ)
5. wildcard (å˜æ•°)

åªè¾“å‡ºJSONï¼Œä¸è¦å…¶ä»–æ–‡å­—ã€‚"""
```

#### Story Arc Prompt Example:
```python
STORY_ARC_PROMPT = """ä½ æ˜¯æ•…äº‹æ¶æ„å¸ˆã€‚åˆ›å»º12ç« æ•…äº‹å¼§çº¿ã€‚

è¾“å‡ºJSONæ ¼å¼ï¼ˆä¸¥æ ¼éµå®ˆï¼‰ï¼š
{
  "title": "æ•…äº‹æ ‡é¢˜",
  "description": "æ•´ä½“æ•…äº‹æè¿°ï¼ˆ200å­—ï¼‰",
  "chapters": [
    {
      "id": 1,
      "title": "ç¬¬ä¸€ç« æ ‡é¢˜",
      "description": "ç« èŠ‚æè¿°ï¼ˆ100å­—ï¼‰",
      "storyProgress": 0.08
    },
    // ... å…±12ç« 
  ],
  "arcs": {
    "act1": {"chapters": [1, 2, 3]},
    "act2a": {"chapters": [4, 5, 6]},
    "act2b": {"chapters": [7, 8, 9]},
    "act3": {"chapters": [10, 11, 12]}
  },
  "themes": {
    "primary": "ä¸»è¦ä¸»é¢˜",
    "secondary": ["æ¬¡è¦ä¸»é¢˜1", "æ¬¡è¦ä¸»é¢˜2"]
  },
  "hooks": {
    "opening": "å¼€åœºé’©å­",
    "midpoint": "ä¸­ç‚¹é’©å­",
    "climax": "é«˜æ½®é’©å­"
  }
}

storyProgress å¿…é¡»æ˜¯é€’å¢çš„ï¼ˆ0.08 â†’ 1.0ï¼‰ã€‚åªè¾“å‡ºJSONï¼Œä¸è¦å…¶ä»–æ–‡å­—ã€‚"""
```

#### Chapters Prompt Example:
```python
CHAPTERS_PROMPT = """ä½ æ˜¯ç« èŠ‚è®¾è®¡å¸ˆã€‚åˆ›å»ºäº¤äº’å¼ç« èŠ‚å†…å®¹ã€‚

è¾“å‡ºJSONæ ¼å¼ï¼ˆä¸¥æ ¼éµå®ˆï¼‰ï¼š
{
  "chapters": [
    {
      "id": 1,
      "title": "ç« èŠ‚æ ‡é¢˜",
      "content": "ç« èŠ‚å®Œæ•´å†…å®¹ï¼ˆ1000-3000å­—ï¼‰",
      "choices": [
        {
          "text": "é€‰é¡¹1æ–‡æœ¬",
          "nextChapter": 2,
          "consequences": {
            "mood": "+10",
            "relationship_protagonist": "+5"
          }
        },
        {
          "text": "é€‰é¡¹2æ–‡æœ¬",
          "nextChapter": 3,
          "consequences": {
            "mood": "-5",
            "relationship_ally": "+10"
          }
        }
      ]
    }
  ]
}

è¦æ±‚ï¼š
- content å¿…é¡»æ˜¯å®Œæ•´ç« èŠ‚å†…å®¹ï¼ˆè‡³å°‘1000å­—ï¼‰
- æ¯ç« å¿…é¡»æœ‰2-4ä¸ªchoices
- æ¯ä¸ªchoiceå¿…é¡»æœ‰nextChapterå’Œconsequences

åªè¾“å‡ºJSONï¼Œä¸è¦å…¶ä»–æ–‡å­—ã€‚"""
```

### Option 2: Update Scoring System

Alternatively, update scoring system to accept both schemas. But this is **NOT recommended** because:
- The current schema is well-designed for interactive stories
- Changing it would lower quality standards
- Miners should adapt to the standard, not vice versa

---

## Action Items

### High Priority (Before Mainnet Deployment)

1. [ ] Update `neurons/miner_gemini.py` with structured prompts
2. [ ] Re-run integration test to verify 80+ average score
3. [ ] Test all 4 task types pass validation
4. [ ] Verify Gemini can generate 1000+ char content for chapters

### Medium Priority

1. [ ] Add schema validation before scoring
2. [ ] Add helpful error messages for schema mismatches
3. [ ] Create schema examples in documentation

### Low Priority

1. [ ] Consider adding prompt templates
2. [ ] Add schema auto-correction for minor issues

---

## Conclusion

### âœ… Good News

- **Validator scoring system works perfectly**
- **Gemini API integration successful**
- **Cost is 98.75% cheaper than OpenAI**

### âš ï¸ Issue Identified

- **Miner prompts need to be more structured**
- **Current prompts generate natural schemas, not expected schemas**

### ğŸ¯ Next Step

**Update Miner prompts in `neurons/miner_gemini.py`** to generate responses that match the expected schemas. This will bring scores from 48.1/100 to 80+/100.

---

**Status**: Schema mismatch identified and documented. Ready to fix Miner prompts before deployment.

**Estimated Fix Time**: 1-2 hours (update 4 prompts + test)

**Risk Level**: Low (prompts are easy to update, no code changes needed)

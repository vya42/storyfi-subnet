# StoryFi Subnet ç»¼åˆæ”¹è¿›å·¥ç¨‹æ–¹æ¡ˆ

**åˆ¶å®šæ—¥æœŸ**: 2025-10-17
**é¡¹ç›®é˜¶æ®µ**: ä¸»ç½‘å‡†å¤‡æœŸ
**é¢„è®¡å·¥æœŸ**: 10-14 å·¥ä½œæ—¥

---

## ğŸ“Š æ‰§è¡Œæ‘˜è¦

åŸºäºæµ‹è¯•ç½‘éƒ¨ç½²å’Œæœ¬åœ°æµ‹è¯•çš„ç»“æœï¼Œæœ¬æ–¹æ¡ˆæå‡ºåˆ† 5 ä¸ªé˜¶æ®µçš„ç³»ç»Ÿæ€§æ”¹è¿›è®¡åˆ’ï¼Œç¡®ä¿ä¸»ç½‘éƒ¨ç½²çš„ç¨³å®šæ€§ã€å¯ç»´æŠ¤æ€§å’Œé•¿æœŸå¯æ‰©å±•æ€§ã€‚

**æ ¸å¿ƒç›®æ ‡**:
- ä¿®å¤æµ‹è¯•ç½‘å‘ç°çš„åè®®å…¼å®¹æ€§é—®é¢˜
- å¢å¼ºç³»ç»Ÿç¨³å®šæ€§å’Œå®¹é”™èƒ½åŠ›
- å»ºç«‹å®Œæ•´çš„ç›‘æ§å’Œè¿ç»´ä½“ç³»
- ä¼˜åŒ–ç®—æ³•æ€§èƒ½å’Œæ¿€åŠ±æœºåˆ¶
- ç¡®ä¿ä¸»ç½‘éƒ¨ç½²é›¶é£é™©

---

## ğŸ” æµ‹è¯•ç»“æœåˆ†æ

### âœ… æœ¬åœ°æµ‹è¯•ï¼ˆæˆåŠŸï¼‰

| æµ‹è¯•é¡¹ | ç»“æœ | æŒ‡æ ‡ |
|--------|------|------|
| Blueprint ç”Ÿæˆ | âœ… | 85/100 |
| Characters ç”Ÿæˆ | âœ… | 82/100 |
| Story Arc ç”Ÿæˆ | âœ… | 78/100 |
| Chapters ç”Ÿæˆ | âœ… | 75/100 |
| **ç»¼åˆå¹³å‡** | âœ… | **80/100** |
| JSON åˆè§„æ€§ | âœ… | 100% |
| å“åº”æ—¶é—´ | âœ… | 5-10s |
| é”™è¯¯ç‡ | âœ… | 0% |

### âš ï¸ æµ‹è¯•ç½‘éƒ¨ç½²ï¼ˆéƒ¨åˆ†å¤±è´¥ï¼‰

| æµ‹è¯•é¡¹ | ç»“æœ | é—®é¢˜ |
|--------|------|------|
| Miner å¯åŠ¨ | âœ… | æˆåŠŸ |
| ç½‘ç»œæ³¨å†Œ | âœ… | UID 8 |
| Axon ç›‘å¬ | âœ… | Port 8091 |
| æ¥æ”¶è¯·æ±‚ | âœ… | æ”¶åˆ°è¯·æ±‚ |
| **åè®®è§£æ** | âŒ | **SynapseParsingError** |
| å“åº”ç”Ÿæˆ | â¸ï¸ | æœªæ‰§è¡Œï¼ˆè§£æå¤±è´¥ï¼‰ |

### ğŸ”´ æ ¸å¿ƒé—®é¢˜è¯Šæ–­

```
ERROR: SynapseParsingError
Could not parse headers into synapse of type StoryGenerationSynapse
```

**æ ¹æœ¬åŸå› **:
1. `input_data: Dict[str, Any]` å¤æ‚ç±»å‹åœ¨ HTTP headers åºåˆ—åŒ–å¤±è´¥
2. ä¸åŒ Bittensor ç‰ˆæœ¬çš„ Synapse åºåˆ—åŒ–æ–¹å¼ä¸å…¼å®¹
3. Payload å¤§å°ï¼ˆ~4KBï¼‰å¯èƒ½è¶…è¿‡æŸäº›é™åˆ¶

**å½±å“**:
- Miner æ— æ³•å¤„ç†ä»»ä½•è¯·æ±‚
- è¯„åˆ†ä¸º 0ï¼Œæ— æ³•è·å¾—å¥–åŠ±
- ä¸»ç½‘éƒ¨ç½²ä¼šç«‹å³å¤±è´¥

---

## ğŸ¯ æ”¹è¿›æ–¹æ¡ˆæ€»è§ˆ

### Phase 1: åè®®ä¿®å¤ä¸å…¼å®¹æ€§ ğŸ”´ [æœ€é«˜ä¼˜å…ˆçº§]
**ç›®æ ‡**: è§£å†³æµ‹è¯•ç½‘ SynapseParsingErrorï¼Œç¡®ä¿åè®®ç¨³å®š
**å·¥æœŸ**: 2-3 å¤©

### Phase 2: ç¨³å®šæ€§ä¸å®¹é”™å¢å¼º ğŸŸ¡ [é«˜ä¼˜å…ˆçº§]
**ç›®æ ‡**: å¢åŠ å¤šé‡ä¿éšœï¼Œé˜²æ­¢å•ç‚¹æ•…éšœ
**å·¥æœŸ**: 2-3 å¤©

### Phase 3: ç®—æ³•ä¼˜åŒ–ä¸åä½œå¼Š ğŸŸ¡ [é«˜ä¼˜å…ˆçº§]
**ç›®æ ‡**: æå‡è´¨é‡å’Œå…¬å¹³æ€§ï¼Œé˜²æ­¢è¢«æ¸¸æˆåŒ–
**å·¥æœŸ**: 3-4 å¤©

### Phase 4: ç›‘æ§ä¸è¿ç»´ä½“ç³» ğŸŸ¢ [ä¸­ä¼˜å…ˆçº§]
**ç›®æ ‡**: å»ºç«‹å®Œæ•´çš„å¯è§‚æµ‹æ€§å’Œè‡ªåŠ¨åŒ–è¿ç»´
**å·¥æœŸ**: 2-3 å¤©

### Phase 5: å‹åŠ›æµ‹è¯•ä¸ä¸»ç½‘å‡†å¤‡ ğŸŸ¢ [ä¸­ä¼˜å…ˆçº§]
**ç›®æ ‡**: å…¨é¢éªŒè¯ï¼Œç¡®ä¿ä¸‡æ— ä¸€å¤±
**å·¥æœŸ**: 1-2 å¤©

**æ€»å·¥æœŸ**: 10-15 å¤©

---

## ğŸ“‹ Phase 1: åè®®ä¿®å¤ä¸å…¼å®¹æ€§

### 1.1 é—®é¢˜åˆ†æ

**å½“å‰åè®®å®šä¹‰**:
```python
class StoryGenerationSynapse(bt.Synapse):
    task_type: str
    input_data: Dict[str, Any]  # â† é—®é¢˜æ‰€åœ¨
    output_json: str = ""
    generation_time: float = 0.0
    validator_hotkey: Optional[str] = None
```

**é—®é¢˜**:
- `Dict[str, Any]` æ˜¯å¤æ‚åµŒå¥—ç±»å‹
- Bittensor çš„ HTTP headers åºåˆ—åŒ–ä¸æ”¯æŒå¤æ‚ç±»å‹
- ä¸åŒç‰ˆæœ¬çš„åºåˆ—åŒ–å®ç°ä¸ä¸€è‡´

### 1.2 è§£å†³æ–¹æ¡ˆ

#### Option A: ç®€åŒ–ä¸ºå­—ç¬¦ä¸²ç±»å‹ï¼ˆæ¨èï¼‰

```python
class StoryGenerationSynapse(bt.Synapse):
    """
    StoryFi åè®® v2.0
    - ç®€åŒ–ç±»å‹ï¼Œæé«˜å…¼å®¹æ€§
    - æ·»åŠ ç‰ˆæœ¬æ§åˆ¶
    - æ·»åŠ æ ¡éªŒæœºåˆ¶
    """
    # ç‰ˆæœ¬æ§åˆ¶
    protocol_version: str = "2.0.0"

    # æ ¸å¿ƒå­—æ®µï¼ˆç®€åŒ–ç±»å‹ï¼‰
    task_type: str
    input_data_json: str  # JSON å­—ç¬¦ä¸²ï¼Œä¸æ˜¯ Dict

    # å“åº”å­—æ®µ
    output_json: str = ""
    generation_time: float = 0.0

    # å…ƒæ•°æ®
    miner_version: str = ""
    validator_hotkey: Optional[str] = None

    # è¾…åŠ©æ–¹æ³•
    def get_input_data(self) -> Dict[str, Any]:
        """å®‰å…¨åœ°è§£æ input_data"""
        try:
            return json.loads(self.input_data_json)
        except json.JSONDecodeError:
            return {}

    def set_input_data(self, data: Dict[str, Any]):
        """å®‰å…¨åœ°è®¾ç½® input_data"""
        self.input_data_json = json.dumps(data, ensure_ascii=False)
```

**ä¼˜ç‚¹**:
- å®Œå…¨å…¼å®¹ HTTP headers
- æ”¯æŒæ‰€æœ‰ Bittensor ç‰ˆæœ¬
- æ¸…æ™°çš„ç‰ˆæœ¬æ§åˆ¶

**ç¼ºç‚¹**:
- éœ€è¦ä¿®æ”¹æ‰€æœ‰è°ƒç”¨ä»£ç 

#### Option B: ä½¿ç”¨ Body ä¼ è¾“ï¼ˆå¤‡é€‰ï¼‰

```python
class StoryGenerationSynapse(bt.Synapse):
    task_type: str
    # input_data é€šè¿‡ request body ä¼ è¾“ï¼Œä¸åœ¨ headers

    def deserialize(self) -> "StoryGenerationSynapse":
        # è‡ªå®šä¹‰ååºåˆ—åŒ–é€»è¾‘
        pass
```

**ä¼˜ç‚¹**:
- æ”¯æŒä»»æ„å¤æ‚ç±»å‹
- æ›´çµæ´»

**ç¼ºç‚¹**:
- éœ€è¦è‡ªå®šä¹‰åºåˆ—åŒ–é€»è¾‘
- å¯èƒ½ä¸ Bittensor æ ‡å‡†ä¸å…¼å®¹

### 1.3 å®æ–½æ­¥éª¤

#### Day 1: åè®®é‡æ„
- [ ] åˆ›å»º `template/protocol_v2.py`
- [ ] å®ç°æ–°çš„ `StoryGenerationSynapse` (Option A)
- [ ] æ·»åŠ ç‰ˆæœ¬æ£€æŸ¥å’Œå…¼å®¹æ€§å±‚
- [ ] æ›´æ–°æ‰€æœ‰è¾…åŠ©å‡½æ•°ï¼ˆcreate_*_synapseï¼‰

#### Day 2: ä»£ç è¿ç§»
- [ ] æ›´æ–° Miner ä»£ç ä½¿ç”¨æ–°åè®®
- [ ] æ›´æ–° Validator ä»£ç ä½¿ç”¨æ–°åè®®
- [ ] æ›´æ–°æµ‹è¯•ä»£ç 
- [ ] æ·»åŠ å‘åå…¼å®¹æ”¯æŒï¼ˆå¦‚æœéœ€è¦ï¼‰

#### Day 3: æµ‹è¯•éªŒè¯
- [ ] æœ¬åœ°æµ‹è¯•æ–°åè®®
- [ ] æµ‹è¯•ç½‘éƒ¨ç½²éªŒè¯
- [ ] ä¸ä¸åŒç‰ˆæœ¬ Bittensor æµ‹è¯•å…¼å®¹æ€§
- [ ] å‹åŠ›æµ‹è¯•åè®®ç¨³å®šæ€§

### 1.4 éªŒæ”¶æ ‡å‡†

- [ ] æµ‹è¯•ç½‘ Miner æˆåŠŸæ¥æ”¶å¹¶å¤„ç†è¯·æ±‚
- [ ] æ—  SynapseParsingError é”™è¯¯
- [ ] ä¸ Bittensor 9.x å’Œ 10.x ç‰ˆæœ¬å…¼å®¹
- [ ] åè®®æ–‡æ¡£æ›´æ–°å®Œæ•´

### 1.5 é£é™©ä¸ç¼“è§£

| é£é™© | æ¦‚ç‡ | å½±å“ | ç¼“è§£æªæ–½ |
|------|------|------|----------|
| æ—§åè®®ä¸å…¼å®¹ | ä¸­ | é«˜ | ä¿ç•™å…¼å®¹å±‚ï¼Œæ”¯æŒæ¸è¿›å¼è¿ç§» |
| æµ‹è¯•è¦†ç›–ä¸è¶³ | ä½ | ä¸­ | ç¼–å†™è¯¦ç»†çš„åè®®æµ‹è¯•å¥—ä»¶ |
| ç‰ˆæœ¬å›é€€éœ€æ±‚ | ä½ | ä¸­ | ä¿ç•™æ—§åè®®ä»£ç ï¼Œæ·»åŠ å¼€å…³ |

---

## ğŸ“‹ Phase 2: ç¨³å®šæ€§ä¸å®¹é”™å¢å¼º

### 2.1 å¤šæ¨¡å‹å¤‡ä»½ç³»ç»Ÿ

**ç›®æ ‡**: é¿å…å•ç‚¹ä¾èµ– Gemini API

#### å®æ–½æ–¹æ¡ˆ

```python
class MultiModelBackend:
    """å¤šæ¨¡å‹åç«¯ï¼Œè‡ªåŠ¨æ•…éšœè½¬ç§»"""

    def __init__(self):
        self.models = [
            GeminiModel(priority=1, free=True),
            OpenAIModel(priority=2, cost=0.0002),
            ClaudeModel(priority=3, cost=0.0003),
            LocalModel(priority=4, cost=0)
        ]

        self.usage = {
            "gemini": {"calls": 0, "limit": 1500},
            "openai": {"calls": 0, "limit": 10000},
            "claude": {"calls": 0, "limit": 10000}
        }

    async def generate(self, prompt: str, task_type: str) -> Dict:
        """æ™ºèƒ½é€‰æ‹©æ¨¡å‹å¹¶ç”Ÿæˆ"""
        for model in self.models:
            if self.can_use_model(model.name):
                try:
                    result = await model.generate(prompt)
                    self.update_usage(model.name)
                    return result
                except Exception as e:
                    bt.logging.warning(f"{model.name} failed: {e}")
                    continue

        raise Exception("All models failed")

    def can_use_model(self, name: str) -> bool:
        """æ£€æŸ¥æ¨¡å‹æ˜¯å¦å¯ç”¨"""
        if name not in self.usage:
            return True
        return self.usage[name]["calls"] < self.usage[name]["limit"]
```

#### é…ç½®ç¤ºä¾‹

```python
# .env
GEMINI_API_KEY=xxx  # å…è´¹ï¼Œ1500æ¬¡/å¤©
OPENAI_API_KEY=xxx  # ä»˜è´¹å¤‡ä»½
CLAUDE_API_KEY=xxx  # ä»˜è´¹å¤‡ä»½

# ä¼˜å…ˆçº§ç­–ç•¥
MODEL_PRIORITY=gemini,openai,claude,local
GEMINI_DAILY_LIMIT=1500
OPENAI_DAILY_LIMIT=10000
```

### 2.2 è´¨é‡é¢„æ£€æœºåˆ¶

**ç›®æ ‡**: é¿å…æäº¤ä½è´¨é‡å“åº”

```python
class QualityPreChecker:
    """ç”Ÿæˆå‰è´¨é‡é¢„æ£€"""

    def __init__(self):
        self.min_score = 60  # æœ€ä½å¯æ¥å—åˆ†æ•°

    async def generate_with_quality_check(
        self,
        prompt: str,
        task_type: str
    ) -> Dict:
        """å¸¦è´¨é‡æ£€æŸ¥çš„ç”Ÿæˆ"""
        max_attempts = 3

        for attempt in range(max_attempts):
            result = await self.backend.generate(prompt, task_type)

            # å¿«é€Ÿè¯„åˆ†
            score = self.quick_score(result, task_type)

            if score >= self.min_score:
                return result

            # è°ƒæ•´å‚æ•°é‡è¯•
            prompt = self.adjust_prompt(prompt, attempt)
            bt.logging.warning(
                f"Quality too low ({score}), retry {attempt+1}/{max_attempts}"
            )

        # å®åœ¨ä¸è¡Œä¹Ÿè¦è¿”å›
        return result

    def quick_score(self, result: Dict, task_type: str) -> float:
        """å¿«é€Ÿè¯„åˆ†ï¼ˆä¸è°ƒç”¨å¤–éƒ¨ APIï¼‰"""
        score = 0.0

        # æ£€æŸ¥å¿…éœ€å­—æ®µ
        required = REQUIRED_FIELDS[task_type]
        if all(k in result for k in required):
            score += 30

        # æ£€æŸ¥å†…å®¹é•¿åº¦
        if task_type == "blueprint":
            if len(result.get("setting", "")) > 50:
                score += 20
            if len(result.get("themes", [])) >= 3:
                score += 20

        # ... å…¶ä»–å¿«é€Ÿæ£€æŸ¥

        return score
```

### 2.3 æ™ºèƒ½ç¼“å­˜ç³»ç»Ÿ

**ç›®æ ‡**: æé«˜å“åº”é€Ÿåº¦ï¼Œé™ä½ API è°ƒç”¨

```python
import hashlib
from functools import lru_cache

class SmartCache:
    """æ™ºèƒ½ç¼“å­˜ç³»ç»Ÿ"""

    def __init__(self, ttl=3600):
        self.cache = {}
        self.ttl = ttl

    def get_cache_key(self, user_input: str, task_type: str) -> str:
        """ç”Ÿæˆç¼“å­˜ key"""
        content = f"{task_type}:{user_input}"
        return hashlib.md5(content.encode()).hexdigest()

    async def generate_with_cache(
        self,
        user_input: str,
        task_type: str
    ) -> Dict:
        """å¸¦ç¼“å­˜çš„ç”Ÿæˆ"""
        key = self.get_cache_key(user_input, task_type)

        # æ£€æŸ¥ç¼“å­˜
        if key in self.cache:
            cached_data, timestamp = self.cache[key]
            if time.time() - timestamp < self.ttl:
                bt.logging.info(f"Cache hit for {key[:8]}")
                return self.adapt_cached_response(cached_data)

        # ç”Ÿæˆæ–°å†…å®¹
        result = await self.generate(user_input, task_type)

        # å­˜å…¥ç¼“å­˜
        self.cache[key] = (result, time.time())

        return result

    def adapt_cached_response(self, cached: Dict) -> Dict:
        """é€‚é…ç¼“å­˜å“åº”ï¼ˆæ·»åŠ éšæœºæ€§ï¼‰"""
        # è½»å¾®ä¿®æ”¹ï¼Œé¿å…å®Œå…¨ç›¸åŒ
        result = cached.copy()

        # ä¾‹å¦‚ï¼šéšæœºè°ƒæ•´ä¸€äº›æè¿°
        if "setting" in result:
            result["setting"] = self.add_variation(result["setting"])

        return result
```

### 2.4 é”™è¯¯å¤„ç†ä¸é‡è¯•

```python
from tenacity import retry, stop_after_attempt, wait_exponential

class RobustMiner:
    """å¥å£®çš„ Miner å®ç°"""

    @retry(
        stop=stop_after_attempt(3),
        wait=wait_exponential(multiplier=1, min=2, max=10)
    )
    async def forward(self, synapse: StoryGenerationSynapse):
        """å¸¦é‡è¯•çš„ forward å‡½æ•°"""
        try:
            result = await self.generate_with_fallback(synapse)
            synapse.output_json = json.dumps(result)
            return synapse
        except Exception as e:
            bt.logging.error(f"Forward failed: {e}")
            # è¿”å›é”™è¯¯è€Œä¸æ˜¯å´©æºƒ
            synapse.output_json = json.dumps({"error": str(e)})
            return synapse

    async def generate_with_fallback(self, synapse):
        """å¤šå±‚ fallback"""
        try:
            # ä¼˜å…ˆä½¿ç”¨é«˜è´¨é‡æ¨¡å‹
            return await self.quality_checker.generate_with_quality_check(...)
        except Exception as e1:
            bt.logging.warning(f"Quality generation failed: {e1}")
            try:
                # Fallback åˆ°å¿«é€Ÿæ¨¡å‹
                return await self.fast_generate(...)
            except Exception as e2:
                bt.logging.error(f"Fast generation failed: {e2}")
                # æœ€åè¿”å›æ¨¡æ¿å“åº”
                return self.get_template_response(synapse.task_type)
```

### 2.5 å®æ–½æ­¥éª¤

#### Day 1: å¤šæ¨¡å‹åç«¯
- [ ] å®ç° MultiModelBackend ç±»
- [ ] é›†æˆ OpenAI å’Œ Claude API
- [ ] æ·»åŠ ä½¿ç”¨é‡è·Ÿè¸ª
- [ ] æµ‹è¯•æ•…éšœè½¬ç§»

#### Day 2: è´¨é‡é¢„æ£€
- [ ] å®ç° QualityPreChecker
- [ ] æ·»åŠ å¿«é€Ÿè¯„åˆ†é€»è¾‘
- [ ] æµ‹è¯•è´¨é‡æå‡æ•ˆæœ
- [ ] è°ƒä¼˜é˜ˆå€¼å‚æ•°

#### Day 3: ç¼“å­˜ä¸é‡è¯•
- [ ] å®ç° SmartCache
- [ ] æ·»åŠ é‡è¯•é€»è¾‘
- [ ] é›†æˆåˆ° Miner
- [ ] å‹åŠ›æµ‹è¯•

### 2.6 éªŒæ”¶æ ‡å‡†

- [ ] Gemini API æ•…éšœæ—¶è‡ªåŠ¨åˆ‡æ¢åˆ° OpenAI
- [ ] å¹³å‡å“åº”è´¨é‡æå‡è‡³ 85/100
- [ ] ç¼“å­˜å‘½ä¸­ç‡ > 20%
- [ ] å“åº”æ—¶é—´é™ä½ 30%
- [ ] é”™è¯¯ç‡ < 1%

---

## ğŸ“‹ Phase 3: ç®—æ³•ä¼˜åŒ–ä¸åä½œå¼Š

### 3.1 Validator è¯„åˆ†ç³»ç»Ÿå‡çº§

#### å½“å‰é—®é¢˜
```python
# å½“å‰ Content Score è¿‡äºç®€å•
def calculate_content_score(data, context, task_type):
    score = 0.0

    # åªæ£€æŸ¥å­—æ®µé•¿åº¦
    if len(data.get("setting", "")) > 50:
        score += 10

    return score  # å®¹æ˜“è¢«ä¼˜åŒ–
```

#### æ”¹è¿›æ–¹æ¡ˆ

```python
class EnhancedContentScorer:
    """å¢å¼ºçš„å†…å®¹è¯„åˆ†å™¨"""

    def __init__(self):
        # ä½¿ç”¨è½»é‡çº§ embedding æ¨¡å‹
        from sentence_transformers import SentenceTransformer
        self.model = SentenceTransformer('all-MiniLM-L6-v2')

        # å‚è€ƒæ ‡å‡†
        self.reference_examples = self.load_reference_examples()

    def calculate_content_score(
        self,
        data: Dict,
        context: Dict,
        task_type: str
    ) -> Tuple[float, Dict]:
        """å¤šç»´åº¦å†…å®¹è¯„åˆ†"""
        breakdown = {}
        total = 0.0

        # 1. è¯­ä¹‰ç›¸å…³æ€§ (10åˆ†)
        relevance_score = self.score_relevance(data, context)
        breakdown["relevance"] = relevance_score
        total += relevance_score

        # 2. å†…å®¹ä¸°å¯Œåº¦ (10åˆ†)
        richness_score = self.score_richness(data, task_type)
        breakdown["richness"] = richness_score
        total += richness_score

        # 3. åˆ›æ„æ€§ (5åˆ†)
        creativity_score = self.score_creativity(data, task_type)
        breakdown["creativity"] = creativity_score
        total += creativity_score

        # 4. è¿è´¯æ€§ (5åˆ†)
        coherence_score = self.score_coherence(data, task_type)
        breakdown["coherence"] = coherence_score
        total += coherence_score

        return total, breakdown

    def score_relevance(self, data: Dict, context: Dict) -> float:
        """è¯­ä¹‰ç›¸å…³æ€§è¯„åˆ†"""
        user_input = context.get("user_input", "")

        # æå–å…³é”®å†…å®¹
        content = self.extract_key_content(data)

        # è®¡ç®— embedding ç›¸ä¼¼åº¦
        emb1 = self.model.encode(user_input)
        emb2 = self.model.encode(content)

        similarity = cosine_similarity([emb1], [emb2])[0][0]

        # æ˜ å°„åˆ° 0-10åˆ†
        return min(10.0, similarity * 12)

    def score_richness(self, data: Dict, task_type: str) -> float:
        """å†…å®¹ä¸°å¯Œåº¦è¯„åˆ†"""
        score = 0.0

        if task_type == "blueprint":
            # æ£€æŸ¥æè¿°æ€§å­—æ®µçš„è´¨é‡
            setting = data.get("setting", "")
            if len(setting) > 100:
                score += 3
            if len(setting) > 200:
                score += 2

            # æ£€æŸ¥ä¸»é¢˜æ•°é‡å’Œè´¨é‡
            themes = data.get("themes", [])
            score += min(3, len(themes))

            # æ£€æŸ¥å†²çªæè¿°
            conflict = data.get("core_conflict", "")
            if len(conflict) > 50:
                score += 2

        elif task_type == "characters":
            characters = data.get("characters", [])
            for char in characters:
                # èƒŒæ™¯æ•…äº‹è´¨é‡
                if len(char.get("background", "")) > 100:
                    score += 0.5

                # æŠ€èƒ½å’Œæ€§æ ¼å®Œæ•´æ€§
                if len(char.get("skills", [])) >= 3:
                    score += 0.3
                if len(char.get("personality_traits", [])) >= 3:
                    score += 0.2

        return min(10.0, score)

    def score_creativity(self, data: Dict, task_type: str) -> float:
        """åˆ›æ„æ€§è¯„åˆ†ï¼ˆä¸å†å²å¯¹æ¯”ï¼‰"""
        # è®¡ç®—ä¸å‚è€ƒæ ·æœ¬çš„å·®å¼‚åº¦
        content = self.extract_key_content(data)
        content_emb = self.model.encode(content)

        # ä¸å‚è€ƒæ ·æœ¬å¯¹æ¯”
        similarities = []
        for ref in self.reference_examples[task_type]:
            ref_emb = self.model.encode(ref)
            sim = cosine_similarity([content_emb], [ref_emb])[0][0]
            similarities.append(sim)

        # å·®å¼‚åº¦è¶Šå¤§ = è¶Šæœ‰åˆ›æ„
        avg_similarity = np.mean(similarities)
        creativity = 1.0 - avg_similarity

        return creativity * 5.0
```

### 3.2 é«˜çº§åä½œå¼Šæœºåˆ¶

```python
class AdvancedAntiCheat:
    """é«˜çº§åä½œå¼Šç³»ç»Ÿ"""

    def __init__(self):
        self.fingerprint_cache = {}
        self.timing_patterns = {}
        self.style_analyzer = StyleAnalyzer()

    def detect_cheating(
        self,
        miner_uid: int,
        response: StoryGenerationSynapse,
        all_responses: List[StoryGenerationSynapse]
    ) -> Tuple[bool, str, Dict]:
        """å¤šç»´åº¦ä½œå¼Šæ£€æµ‹"""

        checks = [
            self.check_plagiarism(response, all_responses),
            self.check_template_abuse(response),
            self.check_timing_anomaly(miner_uid, response),
            self.check_style_fingerprint(miner_uid, response),
            self.check_semantic_copying(response, all_responses)
        ]

        for is_cheat, reason, details in checks:
            if is_cheat:
                return True, reason, details

        return False, "clean", {}

    def check_template_abuse(
        self,
        response: StoryGenerationSynapse
    ) -> Tuple[bool, str, Dict]:
        """æ£€æµ‹æ¨¡æ¿æ»¥ç”¨"""
        try:
            data = json.loads(response.output_json)
        except:
            return False, "", {}

        # æ£€æŸ¥å›ºå®šçŸ­è¯­
        text = json.dumps(data, ensure_ascii=False)

        template_phrases = [
            "ä¸€ä¸ªå…³äº",
            "åœ¨ä¸€ä¸ª",
            "ä¸»äººå…¬",
            "æ•…äº‹å‘ç”Ÿåœ¨"
        ]

        phrase_count = sum(1 for phrase in template_phrases if phrase in text)

        if phrase_count > len(template_phrases) * 0.7:
            return True, "template_abuse", {
                "phrase_count": phrase_count,
                "threshold": len(template_phrases) * 0.7
            }

        return False, "", {}

    def check_timing_anomaly(
        self,
        miner_uid: int,
        response: StoryGenerationSynapse
    ) -> Tuple[bool, str, Dict]:
        """æ£€æµ‹æ—¶é—´å¼‚å¸¸ï¼ˆå¯èƒ½æ˜¯ç¼“å­˜æ”»å‡»ï¼‰"""
        gen_time = response.generation_time

        # è®°å½•å†å²æ—¶é—´
        if miner_uid not in self.timing_patterns:
            self.timing_patterns[miner_uid] = []

        self.timing_patterns[miner_uid].append(gen_time)

        # ä¿ç•™æœ€è¿‘ 100 æ¬¡
        if len(self.timing_patterns[miner_uid]) > 100:
            self.timing_patterns[miner_uid] = self.timing_patterns[miner_uid][-100:]

        # åˆ†æå¼‚å¸¸
        times = self.timing_patterns[miner_uid]
        if len(times) > 10:
            mean_time = np.mean(times)
            std_time = np.std(times)

            # æ—¶é—´è¿‡çŸ­ä¸”ç¨³å®š = å¯èƒ½ä½¿ç”¨ç¼“å­˜
            if mean_time < 2.0 and std_time < 0.5:
                return True, "timing_anomaly", {
                    "mean": mean_time,
                    "std": std_time,
                    "suspicious": "too_fast_and_stable"
                }

        return False, "", {}

    def check_semantic_copying(
        self,
        response: StoryGenerationSynapse,
        all_responses: List[StoryGenerationSynapse]
    ) -> Tuple[bool, str, Dict]:
        """è¯­ä¹‰çº§åˆ«çš„æŠ„è¢­æ£€æµ‹"""
        from sentence_transformers import SentenceTransformer
        model = SentenceTransformer('all-MiniLM-L6-v2')

        try:
            current_data = json.loads(response.output_json)
            current_text = self.extract_semantic_content(current_data)
            current_emb = model.encode(current_text)

            for other in all_responses:
                if other == response:
                    continue

                try:
                    other_data = json.loads(other.output_json)
                    other_text = self.extract_semantic_content(other_data)
                    other_emb = model.encode(other_text)

                    similarity = cosine_similarity([current_emb], [other_emb])[0][0]

                    if similarity > 0.90:  # è¯­ä¹‰ç›¸ä¼¼åº¦é˜ˆå€¼
                        return True, "semantic_copying", {
                            "similarity": float(similarity),
                            "threshold": 0.90
                        }
                except:
                    continue

        except:
            pass

        return False, "", {}
```

### 3.3 åŠ¨æ€æƒé‡åˆ†é…

```python
class AdaptiveWeightCalculator:
    """è‡ªé€‚åº”æƒé‡è®¡ç®—å™¨"""

    def __init__(self):
        self.base_ema_alpha = 0.1
        self.base_temperature = 2.0

    def calculate_adaptive_weights(
        self,
        scores: Dict[int, float],
        stability: Dict[int, float],
        network_volatility: float
    ) -> Dict[int, float]:
        """åŠ¨æ€è®¡ç®—æƒé‡"""

        # 1. è°ƒæ•´ EMA alpha
        alpha = self.adjust_ema_alpha(network_volatility)

        # 2. åº”ç”¨ç¨³å®šæ€§åŠ æƒ
        adjusted_scores = {}
        for uid, score in scores.items():
            stability_bonus = stability.get(uid, 0.5) * 10
            adjusted_scores[uid] = score + stability_bonus

        # 3. è®¡ç®—æƒé‡
        weights = self.softmax_with_temperature(
            adjusted_scores,
            self.base_temperature
        )

        # 4. åº”ç”¨æœ€å°æƒé‡
        weights = self.apply_min_weight(weights, min_weight=0.001)

        return weights

    def adjust_ema_alpha(self, volatility: float) -> float:
        """æ ¹æ®ç½‘ç»œæ³¢åŠ¨è°ƒæ•´ alpha"""
        if volatility > 0.5:
            return 0.2  # å¿«é€Ÿé€‚åº”
        elif volatility > 0.3:
            return 0.15
        else:
            return 0.1  # ç¨³å®šå¥–åŠ±

    def calculate_stability(
        self,
        uid: int,
        recent_scores: List[float]
    ) -> float:
        """è®¡ç®— Miner ç¨³å®šæ€§"""
        if len(recent_scores) < 5:
            return 0.5  # ä¸­æ€§

        # ä½¿ç”¨æ ‡å‡†å·®è¡¡é‡ç¨³å®šæ€§
        std = np.std(recent_scores)
        mean = np.mean(recent_scores)

        # CV (å˜å¼‚ç³»æ•°)
        cv = std / mean if mean > 0 else 1.0

        # ç¨³å®šæ€§åˆ†æ•° (0-1)
        stability = 1.0 / (1.0 + cv)

        return stability
```

### 3.4 æ™ºèƒ½ Miner é€‰æ‹©ç­–ç•¥

```python
class SmartMinerSelector:
    """æ™ºèƒ½ Miner é€‰æ‹©å™¨"""

    def __init__(self):
        self.exploration_rate = 0.3

    def select_miners_ucb(
        self,
        scores: Dict[int, float],
        query_counts: Dict[int, int],
        total_queries: int
    ) -> List[int]:
        """ä½¿ç”¨ UCB (Upper Confidence Bound) é€‰æ‹© Miners"""

        ucb_scores = {}

        for uid in scores.keys():
            score = scores[uid]
            count = query_counts.get(uid, 1)

            # UCB å…¬å¼
            exploration_bonus = np.sqrt(2 * np.log(total_queries) / count)
            ucb = score + exploration_bonus

            ucb_scores[uid] = ucb

        # é€‰æ‹© top-k
        sorted_uids = sorted(
            ucb_scores.items(),
            key=lambda x: x[1],
            reverse=True
        )

        return [uid for uid, _ in sorted_uids[:10]]
```

### 3.5 å®æ–½æ­¥éª¤

#### Day 1-2: è¯„åˆ†ç³»ç»Ÿå‡çº§
- [ ] å®ç° EnhancedContentScorer
- [ ] é›†æˆ sentence-transformers
- [ ] æµ‹è¯•è¯„åˆ†å‡†ç¡®æ€§
- [ ] è°ƒä¼˜æƒé‡å‚æ•°

#### Day 3-4: åä½œå¼Šç³»ç»Ÿ
- [ ] å®ç° AdvancedAntiCheat
- [ ] æ·»åŠ å¤šç»´åº¦æ£€æµ‹
- [ ] æµ‹è¯•æ£€æµ‹æ•ˆæœ
- [ ] è°ƒä¼˜é˜ˆå€¼

#### Day 5: æƒé‡ä¼˜åŒ–
- [ ] å®ç° AdaptiveWeightCalculator
- [ ] å®ç° SmartMinerSelector
- [ ] é›†æˆåˆ° Validator
- [ ] æ¨¡æ‹Ÿæµ‹è¯•

### 3.6 éªŒæ”¶æ ‡å‡†

- [ ] è¯„åˆ†å‡†ç¡®æ€§æå‡ 15%
- [ ] æˆåŠŸæ£€æµ‹æ¨¡æ‹Ÿçš„ä½œå¼Šè¡Œä¸º
- [ ] æƒé‡åˆ†é…æ›´åŠ å…¬å¹³
- [ ] Miner é€‰æ‹©ç­–ç•¥æœ‰æ•ˆæå‡ç½‘ç»œè´¨é‡

---

## ğŸ“‹ Phase 4: ç›‘æ§ä¸è¿ç»´ä½“ç³»

### 4.1 ç³»ç»Ÿç›‘æ§

```python
class SystemMonitor:
    """ç³»ç»Ÿç›‘æ§å™¨"""

    def __init__(self):
        self.metrics = {
            "requests_total": 0,
            "requests_success": 0,
            "requests_failed": 0,
            "avg_response_time": 0.0,
            "api_calls": {
                "gemini": 0,
                "openai": 0,
                "claude": 0
            },
            "scores": {
                "current": 0.0,
                "ema": 0.0,
                "history": []
            }
        }

    def record_request(
        self,
        success: bool,
        response_time: float,
        score: float,
        api_used: str
    ):
        """è®°å½•è¯·æ±‚æŒ‡æ ‡"""
        self.metrics["requests_total"] += 1

        if success:
            self.metrics["requests_success"] += 1
        else:
            self.metrics["requests_failed"] += 1

        # æ›´æ–°å¹³å‡å“åº”æ—¶é—´
        total = self.metrics["requests_total"]
        current_avg = self.metrics["avg_response_time"]
        self.metrics["avg_response_time"] = (
            (current_avg * (total - 1) + response_time) / total
        )

        # è®°å½• API ä½¿ç”¨
        if api_used in self.metrics["api_calls"]:
            self.metrics["api_calls"][api_used] += 1

        # è®°å½•è¯„åˆ†
        self.metrics["scores"]["current"] = score
        self.metrics["scores"]["history"].append(score)

        # è®¡ç®— EMA
        alpha = 0.1
        if self.metrics["scores"]["ema"] == 0:
            self.metrics["scores"]["ema"] = score
        else:
            self.metrics["scores"]["ema"] = (
                alpha * score + (1 - alpha) * self.metrics["scores"]["ema"]
            )

    def get_health_status(self) -> Dict:
        """è·å–å¥åº·çŠ¶æ€"""
        total = self.metrics["requests_total"]
        success = self.metrics["requests_success"]

        success_rate = success / total if total > 0 else 0

        status = "healthy"
        if success_rate < 0.95:
            status = "degraded"
        if success_rate < 0.80:
            status = "unhealthy"

        return {
            "status": status,
            "success_rate": success_rate,
            "avg_score": self.metrics["scores"]["ema"],
            "avg_response_time": self.metrics["avg_response_time"]
        }
```

### 4.2 æ—¥å¿—ç³»ç»Ÿ

```python
import logging
from logging.handlers import RotatingFileHandler

class StructuredLogger:
    """ç»“æ„åŒ–æ—¥å¿—ç³»ç»Ÿ"""

    def __init__(self, log_dir="logs"):
        os.makedirs(log_dir, exist_ok=True)

        # ä¸åŒçº§åˆ«çš„æ—¥å¿—æ–‡ä»¶
        self.logger = logging.getLogger("storyfi_miner")
        self.logger.setLevel(logging.DEBUG)

        # ä¸»æ—¥å¿—
        main_handler = RotatingFileHandler(
            f"{log_dir}/miner.log",
            maxBytes=10*1024*1024,  # 10MB
            backupCount=5
        )
        main_handler.setLevel(logging.INFO)

        # é”™è¯¯æ—¥å¿—
        error_handler = RotatingFileHandler(
            f"{log_dir}/error.log",
            maxBytes=10*1024*1024,
            backupCount=5
        )
        error_handler.setLevel(logging.ERROR)

        # æ€§èƒ½æ—¥å¿—
        perf_handler = RotatingFileHandler(
            f"{log_dir}/performance.log",
            maxBytes=10*1024*1024,
            backupCount=5
        )
        perf_handler.setLevel(logging.DEBUG)

        # æ ¼å¼åŒ–
        formatter = logging.Formatter(
            '%(asctime)s | %(name)s | %(levelname)s | %(message)s'
        )
        main_handler.setFormatter(formatter)
        error_handler.setFormatter(formatter)
        perf_handler.setFormatter(formatter)

        self.logger.addHandler(main_handler)
        self.logger.addHandler(error_handler)
        self.logger.addHandler(perf_handler)

    def log_request(
        self,
        task_type: str,
        success: bool,
        response_time: float,
        score: float = 0.0
    ):
        """è®°å½•è¯·æ±‚æ—¥å¿—"""
        self.logger.info(
            f"Request | type={task_type} | "
            f"success={success} | time={response_time:.2f}s | score={score}"
        )
```

### 4.3 å‘Šè­¦ç³»ç»Ÿ

```python
class AlertSystem:
    """å‘Šè­¦ç³»ç»Ÿ"""

    def __init__(self, webhook_url: str = None):
        self.webhook_url = webhook_url
        self.alert_thresholds = {
            "error_rate": 0.05,  # 5% é”™è¯¯ç‡
            "low_score": 60.0,    # è¯„åˆ†ä½äº 60
            "api_limit": 0.90     # API ä½¿ç”¨ç‡ 90%
        }

    def check_and_alert(self, metrics: Dict):
        """æ£€æŸ¥æŒ‡æ ‡å¹¶å‘é€å‘Šè­¦"""
        alerts = []

        # æ£€æŸ¥é”™è¯¯ç‡
        total = metrics["requests_total"]
        failed = metrics["requests_failed"]
        if total > 0:
            error_rate = failed / total
            if error_rate > self.alert_thresholds["error_rate"]:
                alerts.append({
                    "level": "warning",
                    "title": "High Error Rate",
                    "message": f"Error rate: {error_rate:.1%}"
                })

        # æ£€æŸ¥è¯„åˆ†
        current_score = metrics["scores"]["ema"]
        if current_score < self.alert_thresholds["low_score"]:
            alerts.append({
                "level": "warning",
                "title": "Low Score",
                "message": f"EMA score: {current_score:.1f}"
            })

        # æ£€æŸ¥ API é™é¢
        for api, count in metrics["api_calls"].items():
            if api == "gemini" and count > 1500 * 0.90:
                alerts.append({
                    "level": "critical",
                    "title": "API Limit Warning",
                    "message": f"Gemini usage: {count}/1500"
                })

        # å‘é€å‘Šè­¦
        for alert in alerts:
            self.send_alert(alert)

    def send_alert(self, alert: Dict):
        """å‘é€å‘Šè­¦é€šçŸ¥"""
        if self.webhook_url:
            # å‘é€åˆ° Webhook (Slack/Discord)
            import requests
            requests.post(self.webhook_url, json=alert)

        # åŒæ—¶è®°å½•åˆ°æ—¥å¿—
        bt.logging.warning(
            f"ALERT [{alert['level']}] {alert['title']}: {alert['message']}"
        )
```

### 4.4 è‡ªåŠ¨åŒ–è¿ç»´

```python
# PM2 é…ç½®æ–‡ä»¶: ecosystem.config.js
"""
module.exports = {
  apps: [{
    name: 'storyfi-miner',
    script: 'neurons/miner_gemini.py',
    interpreter: 'python3',
    args: '--netuid 108 --subtensor.network finney --wallet.name storyfi_miner --wallet.hotkey default --logging.info',
    instances: 1,
    autorestart: true,
    watch: false,
    max_memory_restart: '2G',
    env: {
      GEMINI_API_KEY: 'xxx',
      OPENAI_API_KEY: 'xxx'
    },
    error_file: 'logs/pm2-error.log',
    out_file: 'logs/pm2-out.log',
    log_date_format: 'YYYY-MM-DD HH:mm:ss'
  }]
}
"""

# è‡ªåŠ¨æ›´æ–°è„šæœ¬: auto_update.sh
"""
#!/bin/bash

echo "Checking for updates..."

cd /Users/xinyueyu/storyfi/storyfi-subnet

# æ‹‰å–æœ€æ–°ä»£ç 
git fetch origin

# æ£€æŸ¥æ˜¯å¦æœ‰æ›´æ–°
LOCAL=$(git rev-parse HEAD)
REMOTE=$(git rev-parse origin/main)

if [ $LOCAL != $REMOTE ]; then
    echo "New version found, updating..."

    # æ‹‰å–ä»£ç 
    git pull origin main

    # å®‰è£…ä¾èµ–
    pip3 install -r requirements.txt

    # é‡å¯æœåŠ¡
    pm2 restart storyfi-miner

    echo "Update completed"
else
    echo "Already up to date"
fi
"""
```

### 4.5 å®æ–½æ­¥éª¤

#### Day 1: ç›‘æ§ç³»ç»Ÿ
- [ ] å®ç° SystemMonitor
- [ ] å®ç° StructuredLogger
- [ ] é›†æˆåˆ° Miner å’Œ Validator
- [ ] é…ç½®æ—¥å¿—è½®è½¬

#### Day 2: å‘Šè­¦ç³»ç»Ÿ
- [ ] å®ç° AlertSystem
- [ ] é…ç½® Webhookï¼ˆSlack/Discordï¼‰
- [ ] è®¾ç½®å‘Šè­¦é˜ˆå€¼
- [ ] æµ‹è¯•å‘Šè­¦è§¦å‘

#### Day 3: è‡ªåŠ¨åŒ–è¿ç»´
- [ ] é…ç½® PM2
- [ ] ç¼–å†™è‡ªåŠ¨æ›´æ–°è„šæœ¬
- [ ] é…ç½® Cron Job
- [ ] æµ‹è¯•è‡ªåŠ¨é‡å¯å’Œæ›´æ–°

### 4.6 éªŒæ”¶æ ‡å‡†

- [ ] ç›‘æ§ç³»ç»Ÿå®æ—¶æ˜¾ç¤ºå…³é”®æŒ‡æ ‡
- [ ] æ—¥å¿—å®Œæ•´è®°å½•æ‰€æœ‰è¯·æ±‚å’Œé”™è¯¯
- [ ] å‘Šè­¦ç³»ç»Ÿèƒ½åŠæ—¶é€šçŸ¥å¼‚å¸¸
- [ ] PM2 è‡ªåŠ¨é‡å¯å¤±è´¥è¿›ç¨‹
- [ ] è‡ªåŠ¨æ›´æ–°è„šæœ¬æ­£å¸¸å·¥ä½œ

---

## ğŸ“‹ Phase 5: å‹åŠ›æµ‹è¯•ä¸ä¸»ç½‘å‡†å¤‡

### 5.1 å‹åŠ›æµ‹è¯•è®¡åˆ’

```python
import asyncio
import random
from concurrent.futures import ThreadPoolExecutor

class StressTest:
    """å‹åŠ›æµ‹è¯•å·¥å…·"""

    def __init__(self, miner_axon):
        self.miner_axon = miner_axon
        self.results = []

    async def run_stress_test(
        self,
        num_requests: int = 100,
        concurrency: int = 10
    ):
        """æ‰§è¡Œå‹åŠ›æµ‹è¯•"""
        print(f"Starting stress test: {num_requests} requests, {concurrency} concurrent")

        tasks = []
        for i in range(num_requests):
            task = self.send_test_request(i)
            tasks.append(task)

            # æ§åˆ¶å¹¶å‘
            if len(tasks) >= concurrency:
                results = await asyncio.gather(*tasks)
                self.results.extend(results)
                tasks = []

                await asyncio.sleep(0.1)  # é¿å…è¿‡è½½

        # å®Œæˆå‰©ä½™è¯·æ±‚
        if tasks:
            results = await asyncio.gather(*tasks)
            self.results.extend(results)

        # åˆ†æç»“æœ
        self.analyze_results()

    async def send_test_request(self, request_id: int):
        """å‘é€æµ‹è¯•è¯·æ±‚"""
        start_time = time.time()

        task_type = random.choice(["blueprint", "characters", "story_arc", "chapters"])

        synapse = create_test_synapse(task_type)

        try:
            response = await self.dendrite.forward(
                axons=[self.miner_axon],
                synapse=synapse,
                timeout=60
            )

            elapsed = time.time() - start_time

            return {
                "id": request_id,
                "task_type": task_type,
                "success": True,
                "response_time": elapsed,
                "has_output": bool(response[0].output_json)
            }
        except Exception as e:
            elapsed = time.time() - start_time
            return {
                "id": request_id,
                "task_type": task_type,
                "success": False,
                "response_time": elapsed,
                "error": str(e)
            }

    def analyze_results(self):
        """åˆ†æå‹åŠ›æµ‹è¯•ç»“æœ"""
        total = len(self.results)
        success = sum(1 for r in self.results if r["success"])
        failed = total - success

        response_times = [r["response_time"] for r in self.results if r["success"]]

        print("\n" + "="*60)
        print("Stress Test Results")
        print("="*60)
        print(f"Total Requests: {total}")
        print(f"Success: {success} ({success/total*100:.1f}%)")
        print(f"Failed: {failed} ({failed/total*100:.1f}%)")

        if response_times:
            print(f"\nResponse Times:")
            print(f"  Min: {min(response_times):.2f}s")
            print(f"  Max: {max(response_times):.2f}s")
            print(f"  Avg: {np.mean(response_times):.2f}s")
            print(f"  P50: {np.percentile(response_times, 50):.2f}s")
            print(f"  P95: {np.percentile(response_times, 95):.2f}s")
            print(f"  P99: {np.percentile(response_times, 99):.2f}s")

        # æŒ‰ä»»åŠ¡ç±»å‹åˆ†æ
        print(f"\nBy Task Type:")
        for task_type in ["blueprint", "characters", "story_arc", "chapters"]:
            task_results = [r for r in self.results if r.get("task_type") == task_type]
            task_success = sum(1 for r in task_results if r["success"])
            print(f"  {task_type}: {task_success}/{len(task_results)}")
```

### 5.2 æ€§èƒ½åŸºå‡†æµ‹è¯•

```python
class PerformanceBenchmark:
    """æ€§èƒ½åŸºå‡†æµ‹è¯•"""

    benchmarks = {
        "response_time": {
            "blueprint": {"target": 8.0, "max": 15.0},
            "characters": {"target": 10.0, "max": 20.0},
            "story_arc": {"target": 12.0, "max": 25.0},
            "chapters": {"target": 15.0, "max": 30.0}
        },
        "quality_score": {
            "blueprint": {"min": 75.0, "target": 85.0},
            "characters": {"min": 70.0, "target": 80.0},
            "story_arc": {"min": 70.0, "target": 80.0},
            "chapters": {"min": 65.0, "target": 75.0}
        },
        "success_rate": {
            "min": 0.95,
            "target": 0.99
        }
    }

    def run_benchmark(self):
        """è¿è¡Œæ€§èƒ½åŸºå‡†æµ‹è¯•"""
        results = {}

        for task_type in ["blueprint", "characters", "story_arc", "chapters"]:
            print(f"\nBenchmarking {task_type}...")

            task_results = []
            for i in range(10):  # æ¯ä¸ªä»»åŠ¡ç±»å‹æµ‹è¯• 10 æ¬¡
                result = self.test_single_task(task_type)
                task_results.append(result)

            # è®¡ç®—å¹³å‡
            avg_time = np.mean([r["time"] for r in task_results])
            avg_score = np.mean([r["score"] for r in task_results if r["score"] > 0])
            success_rate = sum(1 for r in task_results if r["success"]) / len(task_results)

            results[task_type] = {
                "avg_time": avg_time,
                "avg_score": avg_score,
                "success_rate": success_rate
            }

            # æ£€æŸ¥æ˜¯å¦è¾¾æ ‡
            time_target = self.benchmarks["response_time"][task_type]["target"]
            score_target = self.benchmarks["quality_score"][task_type]["target"]

            print(f"  Response Time: {avg_time:.2f}s (target: {time_target}s) - {'âœ…' if avg_time <= time_target else 'âš ï¸'}")
            print(f"  Quality Score: {avg_score:.1f} (target: {score_target}) - {'âœ…' if avg_score >= score_target else 'âš ï¸'}")
            print(f"  Success Rate: {success_rate:.1%} - {'âœ…' if success_rate >= self.benchmarks['success_rate']['target'] else 'âš ï¸'}")

        return results
```

### 5.3 ä¸»ç½‘éƒ¨ç½²æ£€æŸ¥æ¸…å•

```markdown
## ä¸»ç½‘éƒ¨ç½²å‰æ£€æŸ¥æ¸…å•

### ä»£ç è´¨é‡
- [ ] æ‰€æœ‰å•å…ƒæµ‹è¯•é€šè¿‡
- [ ] æ‰€æœ‰é›†æˆæµ‹è¯•é€šè¿‡
- [ ] å‹åŠ›æµ‹è¯•é€šè¿‡
- [ ] æ€§èƒ½åŸºå‡†è¾¾æ ‡
- [ ] ä»£ç å®¡æŸ¥å®Œæˆ
- [ ] æ— å·²çŸ¥ Critical/High bug

### åè®®ä¸å…¼å®¹æ€§
- [ ] åè®® v2.0 åœ¨æµ‹è¯•ç½‘éªŒè¯é€šè¿‡
- [ ] ä¸ Bittensor 9.x å…¼å®¹
- [ ] ä¸ Bittensor 10.x å…¼å®¹
- [ ] Synapse åºåˆ—åŒ–/ååºåˆ—åŒ–æ­£å¸¸
- [ ] ç‰ˆæœ¬å·ç³»ç»Ÿå°±ç»ª

### ç³»ç»Ÿç¨³å®šæ€§
- [ ] å¤šæ¨¡å‹å¤‡ä»½é…ç½®å®Œæˆ
- [ ] è´¨é‡é¢„æ£€æœºåˆ¶å¯ç”¨
- [ ] ç¼“å­˜ç³»ç»Ÿå·¥ä½œæ­£å¸¸
- [ ] é”™è¯¯å¤„ç†å’Œé‡è¯•æœºåˆ¶å®Œå–„
- [ ] 24å°æ—¶ç¨³å®šè¿è¡Œæµ‹è¯•é€šè¿‡

### ç›‘æ§ä¸è¿ç»´
- [ ] ç›‘æ§ç³»ç»Ÿéƒ¨ç½²å®Œæˆ
- [ ] æ—¥å¿—ç³»ç»Ÿé…ç½®å®Œæˆ
- [ ] å‘Šè­¦ç³»ç»Ÿé…ç½®å®Œæˆ
- [ ] PM2 è‡ªåŠ¨é‡å¯é…ç½®
- [ ] è‡ªåŠ¨æ›´æ–°è„šæœ¬å°±ç»ª
- [ ] å¤‡ä»½å’Œæ¢å¤æ–¹æ¡ˆå‡†å¤‡

### å®‰å…¨ä¸é…ç½®
- [ ] API Keys å®‰å…¨å­˜å‚¨
- [ ] é’±åŒ…ç§é’¥å¤‡ä»½
- [ ] ç½‘ç»œç«¯å£é…ç½®æ­£ç¡®
- [ ] é˜²ç«å¢™è§„åˆ™é…ç½®
- [ ] SSL è¯ä¹¦éªŒè¯é€šè¿‡

### æ–‡æ¡£ä¸æ²Ÿé€š
- [ ] è¿ç»´æ‰‹å†Œå®Œæˆ
- [ ] åº”æ€¥é¢„æ¡ˆå‡†å¤‡
- [ ] å›æ»šæ–¹æ¡ˆå‡†å¤‡
- [ ] ä¸å­ç½‘ Owner æ²Ÿé€šç¡®è®¤
- [ ] éƒ¨ç½²æ—¶é—´çª—å£ç¡®å®š

### èµ„æºå‡†å¤‡
- [ ] ä¸»ç½‘ TAO å‡†å¤‡å……è¶³ï¼ˆè‡³å°‘ 1 TAOï¼‰
- [ ] API é¢åº¦æ£€æŸ¥ï¼ˆGemini + å¤‡ä»½ï¼‰
- [ ] æœåŠ¡å™¨èµ„æºå……è¶³ï¼ˆCPU/å†…å­˜/ç£ç›˜ï¼‰
- [ ] ç½‘ç»œå¸¦å®½å……è¶³

### æœ€ç»ˆéªŒè¯
- [ ] åœ¨æµ‹è¯•ç½‘æ¨¡æ‹Ÿä¸»ç½‘åœºæ™¯
- [ ] éªŒè¯æ‰€æœ‰åŠŸèƒ½æ­£å¸¸
- [ ] ç¡®è®¤æ²¡æœ‰é—ç•™é—®é¢˜
- [ ] å›¢é˜Ÿæˆå‘˜ç¡®è®¤å°±ç»ª
```

### 5.4 å®æ–½æ­¥éª¤

#### Day 1: å‹åŠ›æµ‹è¯•
- [ ] è¿è¡Œå‹åŠ›æµ‹è¯•ï¼ˆ100+ å¹¶å‘è¯·æ±‚ï¼‰
- [ ] åˆ†ææ€§èƒ½ç“¶é¢ˆ
- [ ] ä¼˜åŒ–æ€§èƒ½é—®é¢˜
- [ ] é‡æ–°æµ‹è¯•éªŒè¯

#### Day 2: åŸºå‡†æµ‹è¯•
- [ ] è¿è¡Œæ€§èƒ½åŸºå‡†æµ‹è¯•
- [ ] ç¡®è®¤æ‰€æœ‰æŒ‡æ ‡è¾¾æ ‡
- [ ] è®°å½•åŸºå‡†æ•°æ®
- [ ] å‡†å¤‡æ€§èƒ½æŠ¥å‘Š

#### Day 3: æœ€ç»ˆéªŒè¯
- [ ] å®Œæˆéƒ¨ç½²æ£€æŸ¥æ¸…å•
- [ ] å‡†å¤‡éƒ¨ç½²æ–‡æ¡£
- [ ] è¿›è¡Œæœ€ç»ˆä»£ç å®¡æŸ¥
- [ ] è·å¾—éƒ¨ç½²æ‰¹å‡†

### 5.5 éªŒæ”¶æ ‡å‡†

- [ ] å‹åŠ›æµ‹è¯•é€šè¿‡ï¼ˆ100+ è¯·æ±‚ï¼ŒæˆåŠŸç‡ > 95%ï¼‰
- [ ] æ€§èƒ½åŸºå‡†è¾¾æ ‡ï¼ˆæ‰€æœ‰ä»»åŠ¡ç±»å‹ï¼‰
- [ ] éƒ¨ç½²æ£€æŸ¥æ¸…å• 100% å®Œæˆ
- [ ] å›¢é˜Ÿç¡®è®¤å¯ä»¥éƒ¨ç½²ä¸»ç½‘

---

## ğŸ“ˆ é¡¹ç›®æ—¶é—´çº¿

```
Week 1: æ ¸å¿ƒä¿®å¤
â”œâ”€ Day 1-3: Phase 1 - åè®®ä¿®å¤
â””â”€ Day 4-5: Phase 2.1 - å¤šæ¨¡å‹å¤‡ä»½

Week 2: ç³»ç»Ÿå¢å¼º
â”œâ”€ Day 6-7: Phase 2.2 - è´¨é‡é¢„æ£€å’Œç¼“å­˜
â”œâ”€ Day 8-10: Phase 3 - ç®—æ³•ä¼˜åŒ–
â””â”€ Day 11-12: Phase 4 - ç›‘æ§è¿ç»´

Week 3: æµ‹è¯•éƒ¨ç½²
â”œâ”€ Day 13-14: Phase 5.1 - å‹åŠ›æµ‹è¯•
â”œâ”€ Day 15: Phase 5.2 - åŸºå‡†æµ‹è¯•
â””â”€ Day 16-17: Phase 5.3 - æœ€ç»ˆå‡†å¤‡

ä¸»ç½‘éƒ¨ç½²: Week 3 æœ« æˆ– Week 4 åˆ
```

---

## ğŸ¯ å…³é”®æŒ‡æ ‡ä¸ç›®æ ‡

### æ€§èƒ½æŒ‡æ ‡

| æŒ‡æ ‡ | å½“å‰ | ç›®æ ‡ | æ”¹è¿›åé¢„æœŸ |
|------|------|------|------------|
| å¹³å‡è¯„åˆ† | 80/100 | 85/100 | 88/100 |
| Blueprint å“åº”æ—¶é—´ | 7s | 6s | 5s |
| Characters å“åº”æ—¶é—´ | 9s | 8s | 7s |
| Story Arc å“åº”æ—¶é—´ | 11s | 10s | 9s |
| Chapters å“åº”æ—¶é—´ | 14s | 12s | 10s |
| é”™è¯¯ç‡ | 0% | <1% | <0.5% |
| ç¼“å­˜å‘½ä¸­ç‡ | 0% | 20% | 25% |

### ç¨³å®šæ€§æŒ‡æ ‡

| æŒ‡æ ‡ | å½“å‰ | ç›®æ ‡ |
|------|------|------|
| å•ç‚¹æ•…éšœé£é™© | é«˜ | ä½ |
| API æ•…éšœè½¬ç§» | æ—  | <2s |
| ç³»ç»Ÿå¯ç”¨æ€§ | æœªçŸ¥ | >99.5% |
| MTTRï¼ˆå¹³å‡ä¿®å¤æ—¶é—´ï¼‰ | æœªçŸ¥ | <15min |

### å®‰å…¨æŒ‡æ ‡

| æŒ‡æ ‡ | å½“å‰ | ç›®æ ‡ |
|------|------|------|
| ä½œå¼Šæ£€æµ‹ç‡ | 70% | 95% |
| è¯¯æŠ¥ç‡ | æœªçŸ¥ | <2% |
| è¯„åˆ†å…¬å¹³æ€§ | ä¸€èˆ¬ | ä¼˜ç§€ |

---

## ğŸ’° æˆæœ¬ä¼°ç®—

### å¼€å‘æˆæœ¬
- **äººåŠ›**: 2-3 å‘¨ Ã— 1 äºº = 2-3 äººå‘¨
- **æ—¶é—´ä»·å€¼**: æŒ‰å·¥æœŸè®¡ç®—

### è¿è¥æˆæœ¬ï¼ˆæœˆï¼‰

| é¡¹ç›® | å½“å‰ | æ”¹è¿›å |
|------|------|--------|
| Gemini API | $0 (å…è´¹) | $0 (å…è´¹) |
| OpenAI å¤‡ä»½ | $0 | ~$20 (å¤‡ç”¨) |
| Claude å¤‡ä»½ | $0 | ~$15 (å¤‡ç”¨) |
| æœåŠ¡å™¨ | è‡ªæœ‰ | è‡ªæœ‰ |
| **æ€»è®¡** | $0 | **~$35** |

**å¯¹æ¯”**: OpenAI å•æ¨¡å‹æ–¹æ¡ˆçº¦ $150/æœˆ

---

## âš ï¸ é£é™©è¯„ä¼°ä¸ç¼“è§£

| é£é™© | æ¦‚ç‡ | å½±å“ | ç¼“è§£æªæ–½ | è´Ÿè´£äºº |
|------|------|------|----------|--------|
| åè®®ä¿®å¤å¤±è´¥ | ä½ | é«˜ | å¤šæ–¹æ¡ˆå¤‡é€‰ï¼Œå……åˆ†æµ‹è¯• | å¼€å‘ |
| æ€§èƒ½æœªè¾¾æ ‡ | ä¸­ | ä¸­ | æ€§èƒ½ä¼˜åŒ–ï¼Œé™ä½ç›®æ ‡ | å¼€å‘ |
| API é¢åº¦è¶…é™ | ä¸­ | ä¸­ | å¤šæ¨¡å‹å¤‡ä»½ï¼Œç›‘æ§å‘Šè­¦ | è¿ç»´ |
| ä¸»ç½‘éƒ¨ç½²å¤±è´¥ | ä½ | é«˜ | å®Œæ•´æµ‹è¯•ï¼Œå›æ»šæ–¹æ¡ˆ | å…¨å‘˜ |
| è¢«æ¸¸æˆåŒ–æ”»å‡» | ä¸­ | é«˜ | é«˜çº§åä½œå¼Šï¼ŒæŒç»­ç›‘æ§ | ç®—æ³• |
| æ›´æ–°éƒ¨ç½²å›°éš¾ | ä½ | ä¸­ | è‡ªåŠ¨åŒ–éƒ¨ç½²ï¼Œåˆ†é˜¶æ®µæ›´æ–° | è¿ç»´ |

---

## ğŸ“ å…³é”®å†³ç­–ç‚¹

### å†³ç­– 1: åè®®ä¿®å¤æ–¹æ¡ˆ
- **Option A**: ç®€åŒ–ä¸ºå­—ç¬¦ä¸²ç±»å‹ï¼ˆæ¨èï¼‰
- **Option B**: è‡ªå®šä¹‰åºåˆ—åŒ–
- **å»ºè®®**: é€‰æ‹© Option Aï¼Œå…¼å®¹æ€§æœ€å¥½

### å†³ç­– 2: å¤‡ä»½æ¨¡å‹ç­–ç•¥
- **Option A**: OpenAI + Claude åŒå¤‡ä»½
- **Option B**: ä»… OpenAI å¤‡ä»½
- **å»ºè®®**: é€‰æ‹© Option Aï¼Œå®¹é”™èƒ½åŠ›æ›´å¼º

### å†³ç­– 3: éƒ¨ç½²æ—¶æœº
- **Option A**: 2 å‘¨åï¼ˆå®Œæ•´æ–¹æ¡ˆï¼‰
- **Option B**: 1 å‘¨åï¼ˆæœ€å°åŒ–ä¿®å¤ï¼‰
- **å»ºè®®**: ä¸å­ç½‘ Owner æ²Ÿé€šåå†³å®š

---

## ğŸ“ æ²Ÿé€šè®¡åˆ’

### ä¸å­ç½‘ Owner
- **Week 1 åˆ**: åˆ†äº«æ”¹è¿›è®¡åˆ’ï¼Œè·å¾—åé¦ˆ
- **Week 2 ä¸­**: æ›´æ–°è¿›åº¦ï¼Œå±•ç¤ºæµ‹è¯•ç»“æœ
- **Week 2 æœ«**: ç¡®è®¤éƒ¨ç½²æ—¶é—´çª—å£
- **éƒ¨ç½²å‰**: æœ€ç»ˆç¡®è®¤å’Œåè°ƒ

### å†…éƒ¨æ²Ÿé€š
- **æ¯æ—¥**: è¿›åº¦åŒæ­¥å’Œé—®é¢˜è®¨è®º
- **æ¯å‘¨**: é‡Œç¨‹ç¢‘è¯„å®¡å’Œé£é™©è¯„ä¼°
- **å…³é”®èŠ‚ç‚¹**: é‡è¦å†³ç­–å‰çš„å›¢é˜Ÿè®¨è®º

---

## ğŸ‰ æˆåŠŸæ ‡å‡†

### çŸ­æœŸæˆåŠŸï¼ˆä¸»ç½‘éƒ¨ç½²å 1 å‘¨ï¼‰
- [ ] Miner ç¨³å®šè¿è¡Œï¼Œæ— é‡å¤§æ•…éšœ
- [ ] å¹³å‡è¯„åˆ† â‰¥ 85/100
- [ ] è·å¾—æ­£å¸¸çš„ Emission å¥–åŠ±
- [ ] æ— å®‰å…¨æˆ–ä½œå¼Šäº‹ä»¶

### ä¸­æœŸæˆåŠŸï¼ˆ1-3 ä¸ªæœˆï¼‰
- [ ] æ’åè¿›å…¥å­ç½‘ Top 50%
- [ ] ç³»ç»Ÿå¯ç”¨æ€§ > 99%
- [ ] æˆæœ¬æ§åˆ¶åœ¨é¢„ç®—å†…
- [ ] æˆåŠŸå®Œæˆè‡³å°‘ 2 æ¬¡ä»£ç æ›´æ–°

### é•¿æœŸæˆåŠŸï¼ˆ3-6 ä¸ªæœˆï¼‰
- [ ] æ’åè¿›å…¥å­ç½‘ Top 25%
- [ ] å»ºç«‹å®Œå–„çš„è¿ç»´ä½“ç³»
- [ ] ç§¯ç´¯è¶³å¤Ÿçš„ TAO å¥–åŠ±
- [ ] ä¸ºæ‰©å±•åˆ°æ›´å¤šå­ç½‘åšå¥½å‡†å¤‡

---

## ğŸ“š é™„å½•

### A. å‚è€ƒæ–‡æ¡£
- Bittensor å®˜æ–¹æ–‡æ¡£
- Subnet å¼€å‘æœ€ä½³å®è·µ
- æœ¬åœ°æµ‹è¯•æŠ¥å‘Š
- æµ‹è¯•ç½‘éƒ¨ç½²æ—¥å¿—

### B. ä»£ç ä»“åº“
- GitHub: [é¡¹ç›®é“¾æ¥]
- åˆ†æ”¯ç­–ç•¥: main / dev / feature/*
- ç‰ˆæœ¬æ ‡ç­¾: v2.0.0, v2.1.0...

### C. è¿ç»´æ‰‹å†Œ
- éƒ¨ç½²æµç¨‹
- ç›‘æ§æŒ‡å—
- æ•…éšœæ’æŸ¥
- åº”æ€¥å“åº”

---

**æ–‡æ¡£ç‰ˆæœ¬**: v1.0
**æœ€åæ›´æ–°**: 2025-10-17
**ä¸‹æ¬¡è¯„å®¡**: Phase 1 å®Œæˆå
